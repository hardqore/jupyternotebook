{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7deb00-4c32-467f-8832-dff8bde7f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "my_array = []\n",
    "\n",
    "def get_audit_logs_with_curl(start_date: str, end_date: str, bearer_token: str):\n",
    "    api_endpoint = \"https://appqore.mynglic.com/api/1.0/logs/audit-logs\"\n",
    "\n",
    "    command = [\n",
    "        \"curl\",\n",
    "        \"-s\",  # Suppress progress meter\n",
    "        \"-H\", f\"Authorization: Bearer {bearer_token}\",  # Add bearer token header\n",
    "        f\"{api_endpoint}?startDatetime={start_date}&endDatetime={end_date}\"  # Construct the API URL with query parameters\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Execute the curl command and capture the output\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "        # Return the stdout of the curl command\n",
    "        return result.stdout\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'curl' command not found. Please ensure curl is installed and in your system's PATH.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_files_from_urls(urls: list[str], bearer_token: str = None):\n",
    "    for url in urls:\n",
    "        # Extract the filename from the URL (part after \"/files/\")\n",
    "        filename = url.split(\"/\")[-1]  # Get the last part of the URL after the last '/'\n",
    "        \n",
    "        # Add the .gz extension to the filename\n",
    "        save_filename = f\"{filename}.gz\"\n",
    "\n",
    "        # Construct the curl command\n",
    "        command = [\n",
    "            \"curl\",\n",
    "            \"-s\",  # Suppress progress meter\n",
    "            \"-o\", save_filename,  # Save the downloaded file with the specified filename\n",
    "            url  # The URL to download\n",
    "        ]\n",
    "\n",
    "        # Add bearer token header if provided\n",
    "        if bearer_token:\n",
    "            command.extend([\"-H\", f\"Authorization: Bearer {bearer_token}\"])\n",
    "\n",
    "        try:\n",
    "            # Execute the curl command\n",
    "            subprocess.run(command, check=True)  # check=True raises an exception for non-zero exit codes\n",
    "\n",
    "            print(f\"Downloaded '{url}' and saved as '{save_filename}'\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: 'curl' command not found. Please ensure curl is installed and in your system's PATH.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error downloading '{url}': {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "def get_logfile_urls(start_datetime_str, bearer_token):\n",
    "    start_datetime_obj = datetime.fromisoformat(start_datetime_str.replace(\"Z\", \"+00:00\")) \n",
    "    logfile_urls = []\n",
    "\n",
    "    # Iterate through 24 hours\n",
    "    for hour in range(24):\n",
    "        # Calculate the end datetime (1 hour after the start datetime)\n",
    "        end_datetime_obj = start_datetime_obj + timedelta(hours=1)\n",
    "\n",
    "        # Format the datetimes back to the required string format\n",
    "        start_date_str = start_datetime_obj.isoformat(timespec='milliseconds').replace(\"+00:00\", \"Z\")\n",
    "        end_date_str = end_datetime_obj.isoformat(timespec='milliseconds').replace(\"+00:00\", \"Z\")\n",
    "\n",
    "        # Call the function for the current hour\n",
    "        # NOTE: You'll need to replace 'get_audit_logs_with_curl' with your actual function call\n",
    "        # that fetches audit logs using curl.\n",
    "        output = get_audit_logs_with_curl(start_date_str, end_date_str, bearer_token) \n",
    "\n",
    "        # Process the output (e.g., print it, save it to a file, etc.)\n",
    "        if output:\n",
    "            try:\n",
    "                json_data = json.loads(output)\n",
    "                if 'logLocations' in json_data:\n",
    "                    logfile_urls.extend(json_data['logLocations']) # Use extend to add elements from a list\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error decoding JSON for hour {hour}. Output: {output}\")\n",
    "\n",
    "        # Update the start datetime for the next iteration\n",
    "        start_datetime_obj = end_datetime_obj\n",
    "\n",
    "    return logfile_urls\n",
    "\n",
    "def get_logfile_urls(start_datetime_str, bearer_token):\n",
    "    start_datetime_obj = datetime.fromisoformat(start_datetime_str.replace(\"Z\", \"+00:00\"))\n",
    "    logfile_urls = []\n",
    "\n",
    "    # Iterate through 24 hours\n",
    "    for hour in range(24):\n",
    "        # Calculate the end datetime (1 hour after the start datetime)\n",
    "        end_datetime_obj = start_datetime_obj + timedelta(hours=1)\n",
    "\n",
    "        # Format the datetimes back to the required string format\n",
    "        start_date_str = start_datetime_obj.isoformat(timespec='milliseconds').replace(\"+00:00\", \"Z\")\n",
    "        end_date_str = end_datetime_obj.isoformat(timespec='milliseconds').replace(\"+00:00\", \"Z\")\n",
    "\n",
    "        # Call the function for the current hour\n",
    "        # NOTE: You'll need to replace 'get_audit_logs_with_curl' with your actual function call\n",
    "        # that fetches audit logs using curl.\n",
    "        output = get_audit_logs_with_curl(start_date_str, end_date_str, bearer_token) # Replace with your actual function call\n",
    "\n",
    "        # Process the output (e.g., print it, save it to a file, etc.)\n",
    "        if output:\n",
    "            try:\n",
    "                json_data = json.loads(output)\n",
    "                if 'logLocations' in json_data:\n",
    "                    logfile_urls.extend(json_data['logLocations'])  # Use extend to add elements from a list\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error decoding JSON for hour {hour}. Output: {output}\")\n",
    "\n",
    "        # Update the start datetime for the next iteration\n",
    "        start_datetime_obj = end_datetime_obj\n",
    "\n",
    "    return logfile_urls\n",
    "\n",
    "\n",
    "# Array of start dates\n",
    "start_dates = [\"2024-07-24T00:00:00.000Z\", \"2024-07-25T00:00:00.000Z\"] \n",
    "bearer_token = \"\"  # Replace with your actual token\n",
    "\n",
    "# Loop through the array of start dates\n",
    "for start_date in start_dates:\n",
    "    # Call the function with the current start date and bearer token\n",
    "    urls_for_date = get_logfile_urls(start_date, bearer_token)\n",
    "\n",
    "    # Cumulatively store the results\n",
    "    my_array.extend(urls_for_date) # Use extend for efficient list merging\n",
    "\n",
    "download_files_from_urls(my_array, bearer_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf4358-8da8-4da8-8deb-42b5698beeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
